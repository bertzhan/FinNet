# -*- coding: utf-8 -*-
"""
çˆ¬è™«åŸºç±»
å®šä¹‰ç»Ÿä¸€çš„çˆ¬è™«æ¥å£ï¼Œæ”¯æŒ Aè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡ä¸‰å¤§å¸‚åœº
éµå¾ª plan.md è®¾è®¡ï¼Œé›†æˆ storage å±‚
"""

import uuid
from abc import ABC, abstractmethod
from typing import List, Dict, Optional, Tuple, Union
from datetime import datetime
from dataclasses import dataclass, field
import os

from src.common.constants import Market, DocType, DocumentStatus
from src.common.logger import get_logger, LoggerMixin
from src.common.config import minio_config
from src.storage.object_store.minio_client import MinIOClient
from src.storage.object_store.path_manager import PathManager
from src.storage.metadata.postgres_client import get_postgres_client
from src.storage.metadata import crud
from src.storage.metadata.quarantine_manager import QuarantineManager


@dataclass
class CrawlTask:
    """
    çˆ¬å–ä»»åŠ¡
    """
    stock_code: str                      # è‚¡ç¥¨ä»£ç 
    company_name: str                    # å…¬å¸åç§°
    market: Market                       # å¸‚åœºç±»å‹
    doc_type: DocType                    # æ–‡æ¡£ç±»å‹
    year: Optional[int] = None           # å¹´ä»½ï¼ˆIPOç±»å‹ä¸éœ€è¦ï¼‰
    quarter: Optional[int] = None        # å­£åº¦ (1-4)ï¼ŒNone è¡¨ç¤ºå¹´æŠ¥ï¼ˆIPOç±»å‹ä¸éœ€è¦ï¼‰
    metadata: Dict = field(default_factory=dict)  # é¢å¤–å…ƒæ•°æ®

    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'stock_code': self.stock_code,
            'company_name': self.company_name,
            'market': self.market.value,
            'doc_type': self.doc_type.value,
            'year': self.year,
            'quarter': self.quarter,
            'metadata': self.metadata
        }


@dataclass
class CrawlResult:
    """
    çˆ¬å–ç»“æœ
    """
    task: CrawlTask                      # ä»»åŠ¡ä¿¡æ¯
    success: bool                        # æ˜¯å¦æˆåŠŸ
    local_file_path: Optional[str] = None    # æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼ˆä¸´æ—¶ï¼‰
    minio_object_path: Optional[str] = None  # MinIO å¯¹è±¡è·¯å¾„
    document_id: Optional[Union[uuid.UUID, str]] = None        # æ•°æ®åº“æ–‡æ¡£ ID
    file_size: Optional[int] = None          # æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
    file_hash: Optional[str] = None          # æ–‡ä»¶å“ˆå¸Œ
    error_message: Optional[str] = None      # é”™è¯¯ä¿¡æ¯ï¼ˆå¤±è´¥æ—¶ï¼‰
    metadata: Dict = field(default_factory=dict)  # å…ƒæ•°æ®

    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'task': self.task.to_dict(),
            'success': self.success,
            'local_file_path': self.local_file_path,
            'minio_object_path': self.minio_object_path,
            'document_id': self.document_id,
            'file_size': self.file_size,
            'file_hash': self.file_hash,
            'error_message': self.error_message,
            'metadata': self.metadata
        }


class BaseCrawler(ABC, LoggerMixin):
    """
    çˆ¬è™«åŸºç±»
    æ‰€æœ‰å¸‚åœºçˆ¬è™«éƒ½åº”ç»§æ‰¿æ­¤ç±»å¹¶å®ç°æŠ½è±¡æ–¹æ³•

    é›†æˆåŠŸèƒ½ï¼š
    - è‡ªåŠ¨ä¸Šä¼ åˆ° MinIO
    - è‡ªåŠ¨è®°å½•åˆ° PostgreSQL
    - æ–‡ä»¶å“ˆå¸Œè®¡ç®—
    - è·¯å¾„ç®¡ç†
    """

    def __init__(
        self,
        market: Market,
        enable_minio: bool = True,
        enable_postgres: bool = True,
        enable_quarantine: bool = True
    ):
        """
        Args:
            market: å¸‚åœºç±»å‹
            enable_minio: æ˜¯å¦å¯ç”¨ MinIO ä¸Šä¼ 
            enable_postgres: æ˜¯å¦å¯ç”¨ PostgreSQL è®°å½•
            enable_quarantine: æ˜¯å¦å¯ç”¨è‡ªåŠ¨éš”ç¦»ï¼ˆéªŒè¯å¤±è´¥æ—¶ï¼‰
        """
        self.market = market
        self.enable_minio = enable_minio
        self.enable_postgres = enable_postgres
        self.enable_quarantine = enable_quarantine

        # ä»é…ç½®è¯»å– bucket åç§°ï¼Œç¡®ä¿ PathManager å’Œ MinIOClient ä½¿ç”¨ç›¸åŒçš„ bucket
        self.bucket_name = minio_config.MINIO_BUCKET
        self.logger.info(f"BaseCrawler åˆå§‹åŒ– - ä»é…ç½®è¯»å– bucket: '{self.bucket_name}' (ç¯å¢ƒå˜é‡ MINIO_BUCKET: {os.getenv('MINIO_BUCKET', 'æœªè®¾ç½®')})")

        # åˆå§‹åŒ–ç»„ä»¶
        self.path_manager = PathManager(bucket=self.bucket_name)

        if self.enable_minio:
            try:
                self.minio_client = MinIOClient(bucket=self.bucket_name)
                self.logger.info(f"MinIO å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼Œbucket: {self.bucket_name}")
            except Exception as e:
                self.logger.warning(f"MinIO å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
                self.enable_minio = False
                self.minio_client = None
        else:
            self.minio_client = None

        if self.enable_postgres:
            try:
                self.pg_client = get_postgres_client()
                self.logger.info("PostgreSQL å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                self.logger.warning(f"PostgreSQL å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
                self.enable_postgres = False
                self.pg_client = None
        else:
            self.pg_client = None

        # åˆå§‹åŒ–éš”ç¦»ç®¡ç†å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.enable_quarantine and self.enable_minio and self.enable_postgres:
            try:
                self.quarantine_manager = QuarantineManager(
                    minio_client=self.minio_client,
                    path_manager=self.path_manager
                )
                self.logger.info("éš”ç¦»ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                self.logger.warning(f"éš”ç¦»ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
                self.enable_quarantine = False
                self.quarantine_manager = None
        else:
            self.quarantine_manager = None

    @abstractmethod
    def _download_file(self, task: CrawlTask) -> Tuple[bool, Optional[str], Optional[str]]:
        """
        ä¸‹è½½æ–‡ä»¶ï¼ˆç”±å­ç±»å®ç°ï¼‰

        Args:
            task: çˆ¬å–ä»»åŠ¡

        Returns:
            (æ˜¯å¦æˆåŠŸ, æœ¬åœ°æ–‡ä»¶è·¯å¾„, é”™è¯¯ä¿¡æ¯)
        """
        pass

    def _prepare_minio_metadata(self, task: CrawlTask) -> Dict[str, str]:
        """
        å‡†å¤‡MinIOä¸Šä¼ çš„metadataï¼Œç»Ÿä¸€æ ¼å¼ï¼šåªä¿ç•™source_urlå’Œpublish_date
        
        Args:
            task: çˆ¬å–ä»»åŠ¡
            
        Returns:
            ç»Ÿä¸€çš„metadataå­—å…¸ï¼ŒåªåŒ…å«source_urlå’Œpublish_dateï¼ˆISOæ ¼å¼å­—ç¬¦ä¸²ï¼‰
        """
        metadata = {}
        
        # æå–source_url
        if task.metadata:
            source_url = task.metadata.get('source_url') or task.metadata.get('doc_url') or task.metadata.get('pdf_url')
            if source_url:
                metadata['source_url'] = str(source_url)
        
        # æå–publish_dateï¼ˆè½¬æ¢ä¸ºISOæ ¼å¼å­—ç¬¦ä¸²ï¼‰
        if task.metadata:
            # ä¼˜å…ˆä½¿ç”¨ISOæ ¼å¼çš„æ—¥æœŸå­—æ®µ
            date_str = task.metadata.get('publication_date_iso') or task.metadata.get('pub_date_iso') or task.metadata.get('publish_date_iso')
            if date_str:
                # å¦‚æœå·²ç»æ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥ä½¿ç”¨
                if isinstance(date_str, str):
                    metadata['publish_date'] = date_str
                # å¦‚æœæ˜¯datetimeå¯¹è±¡ï¼Œè½¬æ¢ä¸ºISOæ ¼å¼å­—ç¬¦ä¸²
                elif isinstance(date_str, datetime):
                    metadata['publish_date'] = date_str.isoformat()
        
        return metadata

    def crawl(self, task: CrawlTask) -> CrawlResult:
        """
        æ‰§è¡Œå•ä¸ªçˆ¬å–ä»»åŠ¡

        å®Œæ•´æµç¨‹ï¼š
        0. æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å·²å­˜åœ¨ï¼ˆé¿å…é‡å¤çˆ¬å–ï¼‰
        1. ä¸‹è½½æ–‡ä»¶åˆ°æœ¬åœ°
        2. è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
        3. ä¸Šä¼ åˆ° MinIOï¼ˆå¦‚æœå¯ç”¨ï¼‰
        4. è®°å½•åˆ° PostgreSQLï¼ˆå¦‚æœå¯ç”¨ï¼‰

        Args:
            task: çˆ¬å–ä»»åŠ¡

        Returns:
            çˆ¬å–ç»“æœ
        """
        if task.doc_type == DocType.IPO_PROSPECTUS:
            self.logger.info(f"å¼€å§‹çˆ¬å–: {task.stock_code} IPOæ‹›è‚¡è¯´æ˜ä¹¦")
        else:
            self.logger.info(f"å¼€å§‹çˆ¬å–: {task.stock_code} {task.year} Q{task.quarter}")

        # 0. æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å·²å­˜åœ¨ï¼ˆé¿å…é‡å¤çˆ¬å–ï¼‰
        if self.enable_postgres and self.pg_client:
            try:
                with self.pg_client.get_session() as session:
                    existing_doc = crud.get_document_by_task(
                        session=session,
                        stock_code=task.stock_code,
                        market=task.market.value,
                        doc_type=task.doc_type.value,
                        year=task.year,
                        quarter=task.quarter
                    )
                    
                    if existing_doc:
                        # æ–‡æ¡£å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½
                        if task.doc_type == DocType.IPO_PROSPECTUS:
                            self.logger.info(
                                f"âœ… æ–‡æ¡£å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½: {task.stock_code} IPOæ‹›è‚¡è¯´æ˜ä¹¦ "
                                f"(id={existing_doc.id}, path={existing_doc.minio_object_path})"
                            )
                        else:
                            self.logger.info(
                                f"âœ… æ–‡æ¡£å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½: {task.stock_code} {task.year} Q{task.quarter} "
                                f"(id={existing_doc.id}, path={existing_doc.minio_object_path})"
                            )
                        
                        # è¿”å›å·²å­˜åœ¨çš„æ–‡æ¡£ä¿¡æ¯
                        return CrawlResult(
                            task=task,
                            success=True,
                            minio_object_path=existing_doc.minio_object_path,
                            document_id=existing_doc.id,
                            file_size=existing_doc.file_size,
                            file_hash=existing_doc.file_hash,
                            metadata=task.metadata
                        )
            except Exception as e:
                # æ£€æŸ¥å¤±è´¥ä¸å½±å“çˆ¬å–æµç¨‹ï¼Œè®°å½•è­¦å‘Šåç»§ç»­
                self.logger.warning(f"âš ï¸ æ£€æŸ¥æ•°æ®åº“æ—¶å‘ç”Ÿå¼‚å¸¸ï¼Œç»§ç»­çˆ¬å–: {e}")

        # 1. ä¸‹è½½æ–‡ä»¶
        success, local_file_path, error_message = self._download_file(task)

        if not success:
            error_msg = error_message or "æœªçŸ¥é”™è¯¯"
            self.logger.error(
                f"ä¸‹è½½å¤±è´¥: {task.stock_code} ({task.company_name}) "
                f"{task.year if task.year else 'N/A'} Q{task.quarter if task.quarter else 'N/A'} - {error_msg}"
            )
            return CrawlResult(
                task=task,
                success=False,
                error_message=error_msg
            )

        # 2. è¯»å–metadataæ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼Œå°†URLç­‰ä¿¡æ¯æ·»åŠ åˆ°task.metadata
        metadata_file = local_file_path.replace('.pdf', '.meta.json').replace('.html', '.meta.json').replace('.htm', '.meta.json')
        if os.path.exists(metadata_file):
            try:
                import json
                with open(metadata_file, 'r', encoding='utf-8') as f:
                    metadata_info = json.load(f)
                    # å°†URLç­‰ä¿¡æ¯æ·»åŠ åˆ°task.metadata
                    if 'source_url' in metadata_info:
                        task.metadata['source_url'] = metadata_info['source_url']
                    # ä¿ç•™å…¶ä»–metadataå­—æ®µï¼ˆå¦‚publication_dateç­‰ï¼‰
                    for key, value in metadata_info.items():
                        if key not in task.metadata:
                            task.metadata[key] = value
            except Exception as e:
                self.logger.warning(f"è¯»å–metadataæ–‡ä»¶å¤±è´¥: {e}")

        # 3. è®¡ç®—æ–‡ä»¶å“ˆå¸Œå’Œå¤§å°
        try:
            from src.common.utils import calculate_file_hash
            from pathlib import Path

            file_hash = calculate_file_hash(local_file_path, algorithm='md5')
            file_size = Path(local_file_path).stat().st_size

            self.logger.debug(f"æ–‡ä»¶ä¿¡æ¯: size={file_size}, hash={file_hash[:16]}...")
        except Exception as e:
            self.logger.error(f"è®¡ç®—æ–‡ä»¶ä¿¡æ¯å¤±è´¥: {e}")
            file_hash = None
            file_size = None

        # 4. ç”Ÿæˆ MinIO è·¯å¾„
        if task.doc_type == DocType.IPO_PROSPECTUS:
            # IPOæ‹›è‚¡è¯´æ˜ä¹¦ï¼šä»ä¸‹è½½çš„æ–‡ä»¶åä¸­æå–å®é™…æ–‡ä»¶å
            actual_filename = os.path.basename(local_file_path)
            minio_object_path = self.path_manager.get_bronze_path(
                market=task.market,
                doc_type=task.doc_type,
                stock_code=task.stock_code,
                year=None,
                quarter=None,
                filename=actual_filename
            )
        else:
            filename = "document.pdf"
            minio_object_path = self.path_manager.get_bronze_path(
                market=task.market,
                doc_type=task.doc_type,
                stock_code=task.stock_code,
                year=task.year,
                quarter=task.quarter,
                filename=filename
            )

        # 5. ä¸Šä¼ åˆ° MinIO
        document_id = None
        if not self.enable_minio:
            self.logger.warning(f"âš ï¸ MinIO æœªå¯ç”¨ï¼Œè·³è¿‡ä¸Šä¼ : {minio_object_path}")
        elif not self.minio_client:
            self.logger.error(f"âŒ MinIO å®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œæ— æ³•ä¸Šä¼ : {minio_object_path}")
        else:
            try:
                self.logger.info(f"å¼€å§‹ä¸Šä¼ åˆ° MinIO: {minio_object_path}")
                # ç»Ÿä¸€metadataæ ¼å¼ï¼šåªä¿ç•™source_urlå’Œpublish_date
                minio_metadata = self._prepare_minio_metadata(task)
                upload_success = self.minio_client.upload_file(
                    object_name=minio_object_path,
                    file_path=local_file_path,
                    metadata=minio_metadata
                )

                if upload_success:
                    self.logger.info(f"âœ… MinIO ä¸Šä¼ æˆåŠŸ: {minio_object_path}")
                else:
                    self.logger.error(f"âŒ MinIO ä¸Šä¼ å¤±è´¥ï¼ˆè¿”å› Falseï¼‰: {minio_object_path}")
            except Exception as e:
                self.logger.error(f"âŒ MinIO ä¸Šä¼ å¼‚å¸¸: {e}", exc_info=True)

        # 6. è®°å½•åˆ° PostgreSQL
        if self.enable_postgres and self.pg_client:
            try:
                with self.pg_client.get_session() as session:
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                    existing_doc = crud.get_document_by_path(session, minio_object_path)

                    if existing_doc:
                        self.logger.info(f"æ–‡æ¡£å·²å­˜åœ¨: id={existing_doc.id}")
                        document_id = existing_doc.id
                    else:
                        # å¯¹äºIPOç±»å‹ï¼Œä»æ–‡ä»¶åä¸­æå–å¹´ä»½
                        year = task.year
                        if task.doc_type == DocType.IPO_PROSPECTUS and not year:
                            # ä»æ–‡ä»¶åæå–å¹´ä»½ï¼ˆæ ¼å¼ï¼šcode_year_date.extï¼‰
                            filename = os.path.basename(local_file_path)
                            parts = filename.replace(".pdf", "").replace(".html", "").replace(".htm", "").split("_")
                            if len(parts) > 1 and parts[1].isdigit():
                                year = int(parts[1])
                            else:
                                # å¦‚æœæ— æ³•æå–ï¼Œä½¿ç”¨å½“å‰å¹´ä»½ä½œä¸ºé»˜è®¤å€¼
                                from datetime import datetime
                                year = datetime.now().year
                        
                        # åˆ›å»ºæ–°è®°å½•
                        doc = crud.create_document(
                            session=session,
                            stock_code=task.stock_code,
                            company_name=task.company_name,
                            market=task.market.value,
                            doc_type=task.doc_type.value,
                            year=year if year else datetime.now().year,  # ç¡®ä¿yearä¸ä¸ºNone
                            quarter=task.quarter if task.quarter else None,
                            minio_object_path=minio_object_path,
                            file_size=file_size,
                            file_hash=file_hash,
                            metadata=task.metadata
                        )
                        document_id = doc.id
                        self.logger.info(f"âœ… PostgreSQL è®°å½•æˆåŠŸ: id={document_id}")
            except Exception as e:
                self.logger.error(f"âŒ PostgreSQL è®°å½•å¼‚å¸¸: {e}", exc_info=True)
                # è®°å½•å¤±è´¥ä½†ä¸å½±å“æ•´ä½“æˆåŠŸçŠ¶æ€ï¼ˆå› ä¸º MinIO ä¸Šä¼ å·²æˆåŠŸï¼‰
                document_id = None

        # 7. åˆ›å»ºç»“æœå¯¹è±¡
        result = CrawlResult(
            task=task,
            success=True,
            local_file_path=local_file_path,
            minio_object_path=minio_object_path,
            document_id=document_id,
            file_size=file_size,
            file_hash=file_hash,
            metadata=task.metadata
        )

        # 8. éªŒè¯ç»“æœï¼ˆå¦‚æœå¯ç”¨è‡ªåŠ¨éš”ç¦»ï¼‰
        if self.enable_quarantine and self.quarantine_manager:
            is_valid, error_msg = self.validate_result(result)
            
            if not is_valid:
                # éªŒè¯å¤±è´¥ï¼Œè‡ªåŠ¨éš”ç¦»
                self.logger.warning(f"éªŒè¯å¤±è´¥ï¼Œè‡ªåŠ¨éš”ç¦»: {error_msg}")
                try:
                    self.quarantine_manager.quarantine_document(
                        document_id=document_id,
                        source_type=task.market.value,
                        doc_type=task.doc_type.value,
                        original_path=minio_object_path,
                        failure_stage="validation_failed",
                        failure_reason=error_msg or "éªŒè¯å¤±è´¥",
                        failure_details=f"æ–‡ä»¶å¤§å°: {file_size} bytes, æ–‡ä»¶å“ˆå¸Œ: {file_hash}",
                        extra_metadata={
                            "stock_code": task.stock_code,
                            "company_name": task.company_name,
                            "year": task.year,
                            "quarter": task.quarter
                        }
                    )
                    self.logger.info(f"âœ… æ–‡æ¡£å·²è‡ªåŠ¨éš”ç¦»: {minio_object_path}")
                except Exception as e:
                    self.logger.error(f"âŒ è‡ªåŠ¨éš”ç¦»å¤±è´¥: {e}", exc_info=True)

        # 8. è¿”å›ç»“æœ
        return result

    def crawl_batch(self, tasks: List[CrawlTask]) -> List[CrawlResult]:
        """
        æ‰¹é‡çˆ¬å–

        Args:
            tasks: ä»»åŠ¡åˆ—è¡¨

        Returns:
            ç»“æœåˆ—è¡¨
        """
        self.logger.info(f"å¼€å§‹æ‰¹é‡çˆ¬å–: {len(tasks)} ä¸ªä»»åŠ¡")

        results = []
        total = len(tasks)

        for idx, task in enumerate(tasks):
            # æ˜¾ç¤ºè¿›åº¦ï¼šæ¯10ä¸ªæˆ–æ¯10%æ˜¾ç¤ºä¸€æ¬¡ï¼Œæˆ–æœ€åä¸€ä¸ª
            if (idx + 1) % 10 == 0 or (idx + 1) % max(1, total // 10) == 0 or (idx + 1) == total:
                progress_pct = (idx + 1) / total * 100
                self.logger.info(
                    f"ğŸ“¦ [{idx+1}/{total}] {progress_pct:.1f}% | "
                    f"çˆ¬å–: {task.stock_code} - {task.company_name} "
                    f"{task.year}Q{task.quarter if task.quarter else ''}"
                )

            result = self.crawl(task)
            results.append(result)

        # ç»Ÿè®¡ç»“æœ
        success_count = sum(1 for r in results if r.success)
        fail_count = len(results) - success_count

        self.logger.info(f"æ‰¹é‡çˆ¬å–å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {fail_count}")

        return results

    def validate_result(self, result: CrawlResult) -> Tuple[bool, Optional[str]]:
        """
        éªŒè¯çˆ¬å–ç»“æœ

        Args:
            result: çˆ¬å–ç»“æœ

        Returns:
            (æ˜¯å¦é€šè¿‡éªŒè¯, é”™è¯¯ä¿¡æ¯)
        """
        if not result.success:
            return False, result.error_message

        if not result.local_file_path:
            return False, "æœ¬åœ°æ–‡ä»¶è·¯å¾„ä¸ºç©º"

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        from pathlib import Path
        if not Path(result.local_file_path).exists():
            return False, "æœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨"

        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        if result.file_size and result.file_size < 1024:  # å°äº 1KB
            return False, f"æ–‡ä»¶å¤ªå°: {result.file_size} bytes"

        return True, None
