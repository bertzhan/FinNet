# -*- coding: utf-8 -*-
"""
å‘é‡åŒ–ä½œä¸šå¿«é€Ÿæµ‹è¯•
æµ‹è¯•åŸºæœ¬åŠŸèƒ½å’Œæ•°æ®åº“æŸ¥è¯¢
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(project_root))

from src.storage.metadata.postgres_client import get_postgres_client
from src.storage.metadata.models import DocumentChunk, Document
from src.storage.vector.milvus_client import get_milvus_client
from src.common.constants import MilvusCollection


def check_unvectorized_chunks():
    """æ£€æŸ¥æœªå‘é‡åŒ–çš„åˆ†å—"""
    print("=" * 60)
    print("æ£€æŸ¥æœªå‘é‡åŒ–çš„åˆ†å—")
    print("=" * 60)
    print()
    
    pg_client = get_postgres_client()
    
    try:
        with pg_client.get_session() as session:
            # æŸ¥æ‰¾æœªå‘é‡åŒ–çš„åˆ†å—
            query = session.query(DocumentChunk).join(
                Document, DocumentChunk.document_id == Document.id
            ).filter(
                DocumentChunk.vector_id.is_(None)
            )
            
            total_count = query.count()
            chunks = query.limit(10).all()
            
            print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
            print(f"   æœªå‘é‡åŒ–åˆ†å—æ€»æ•°: {total_count}")
            print(f"   æ˜¾ç¤ºå‰ {len(chunks)} ä¸ªåˆ†å—")
            print()
            
            if not chunks:
                print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°æœªå‘é‡åŒ–çš„åˆ†å—")
                print("   å¯èƒ½åŸå› ï¼š")
                print("   - æ‰€æœ‰åˆ†å—éƒ½å·²å‘é‡åŒ–")
                print("   - è¿˜æ²¡æœ‰åˆ†å—æ•°æ®")
                return []
            
            print("å‰10ä¸ªæœªå‘é‡åŒ–åˆ†å—:")
            for i, chunk in enumerate(chunks, 1):
                doc = session.query(Document).filter(
                    Document.id == chunk.document_id
                ).first()
                print(f"   {i}. chunk_id={chunk.id}")
                print(f"      document_id={chunk.document_id}")
                print(f"      stock_code={doc.stock_code if doc else 'N/A'}")
                print(f"      chunk_index={chunk.chunk_index}")
                print(f"      text_length={len(chunk.chunk_text)}")
                print(f"      text_preview={chunk.chunk_text[:50]}...")
                print()
            
            return chunks
    except Exception as e:
        print(f"âŒ æ£€æŸ¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return []


def check_vectorized_chunks():
    """æ£€æŸ¥å·²å‘é‡åŒ–çš„åˆ†å—"""
    print("=" * 60)
    print("æ£€æŸ¥å·²å‘é‡åŒ–çš„åˆ†å—")
    print("=" * 60)
    print()
    
    pg_client = get_postgres_client()
    
    try:
        with pg_client.get_session() as session:
            # æŸ¥æ‰¾å·²å‘é‡åŒ–çš„åˆ†å—
            query = session.query(DocumentChunk).filter(
                DocumentChunk.vector_id.isnot(None)
            )
            
            total_count = query.count()
            chunks = query.limit(5).all()
            
            print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
            print(f"   å·²å‘é‡åŒ–åˆ†å—æ€»æ•°: {total_count}")
            print(f"   æ˜¾ç¤ºå‰ {len(chunks)} ä¸ªåˆ†å—")
            print()
            
            if not chunks:
                print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°å·²å‘é‡åŒ–çš„åˆ†å—")
                return []
            
            print("å‰5ä¸ªå·²å‘é‡åŒ–åˆ†å—:")
            for i, chunk in enumerate(chunks, 1):
                print(f"   {i}. chunk_id={chunk.id}")
                print(f"      vector_id={chunk.vector_id}")
                print(f"      embedding_model={chunk.embedding_model}")
                print(f"      vectorized_at={chunk.vectorized_at}")
                print()
            
            return chunks
    except Exception as e:
        print(f"âŒ æ£€æŸ¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return []


def check_milvus_collection():
    """æ£€æŸ¥ Milvus Collection"""
    print("=" * 60)
    print("æ£€æŸ¥ Milvus Collection")
    print("=" * 60)
    print()
    
    try:
        milvus_client = get_milvus_client()
        collection_name = MilvusCollection.DOCUMENTS
        
        # æ£€æŸ¥ Collection æ˜¯å¦å­˜åœ¨
        collection = milvus_client.get_collection(collection_name)
        
        if collection:
            print(f"âœ… Collection å­˜åœ¨: {collection_name}")
            
            # è·å–ç»Ÿè®¡ä¿¡æ¯
            stats = milvus_client.get_collection_stats(collection_name)
            print(f"   å‘é‡æ•°é‡: {stats.get('row_count', 0)}")
            print()
            return True
        else:
            print(f"âš ï¸  Collection ä¸å­˜åœ¨: {collection_name}")
            print(f"   Vectorizer ä¼šåœ¨é¦–æ¬¡ä½¿ç”¨æ—¶è‡ªåŠ¨åˆ›å»º")
            print()
            return False
    except Exception as e:
        print(f"âŒ Milvus Collection æ£€æŸ¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_dagster_scan_op():
    """æµ‹è¯• Dagster scan_op"""
    print("=" * 60)
    print("æµ‹è¯• Dagster scan_unvectorized_chunks_op")
    print("=" * 60)
    print()
    
    try:
        from src.processing.compute.dagster.jobs.vectorize_jobs import (
            scan_unvectorized_chunks_op,
        )
        from dagster import build_op_context
        
        # æµ‹è¯• scan_op
        print("æ‰§è¡Œ scan_unvectorized_chunks_op...")
        context = build_op_context(
            config={
                "batch_size": 10,
                "limit": 20,
            }
        )
        scan_result = scan_unvectorized_chunks_op(context)
        
        if scan_result.get("success"):
            print(f"âœ… æ‰«ææˆåŠŸ")
            print(f"   æ‰¾åˆ°åˆ†å—æ•°: {scan_result.get('total_chunks', 0)}")
            print(f"   æ‰¹æ¬¡æ•°: {scan_result.get('total_batches', 0)}")
            
            chunks = scan_result.get("chunks", [])
            if chunks:
                print(f"\nå‰3ä¸ªåˆ†å—ä¿¡æ¯:")
                for i, chunk_info in enumerate(chunks[:3], 1):
                    print(f"   {i}. chunk_id={chunk_info.get('chunk_id')}")
                    print(f"      stock_code={chunk_info.get('stock_code')}")
                    print(f"      chunk_index={chunk_info.get('chunk_index')}")
        else:
            print(f"âš ï¸  æ‰«æå¤±è´¥: {scan_result.get('error_message')}")
        print()
        
        return scan_result.get("success", False)
    except Exception as e:
        print(f"âŒ Dagster scan_op æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\n" + "=" * 60)
    print("å‘é‡åŒ–ä½œä¸šå¿«é€Ÿæµ‹è¯•")
    print("=" * 60)
    print()
    
    results = []
    
    # 1. æ£€æŸ¥æœªå‘é‡åŒ–çš„åˆ†å—
    chunks = check_unvectorized_chunks()
    results.append(("æœªå‘é‡åŒ–åˆ†å—æ£€æŸ¥", len(chunks) >= 0))
    
    # 2. æ£€æŸ¥å·²å‘é‡åŒ–çš„åˆ†å—
    vectorized = check_vectorized_chunks()
    results.append(("å·²å‘é‡åŒ–åˆ†å—æ£€æŸ¥", len(vectorized) >= 0))
    
    # 3. æ£€æŸ¥ Milvus Collection
    results.append(("Milvus Collection", check_milvus_collection()))
    
    # 4. æµ‹è¯• Dagster scan_op
    results.append(("Dagster scan_op", test_dagster_scan_op()))
    
    # æ±‡æ€»ç»“æœ
    print("=" * 60)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 60)
    print()
    
    for name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{status}: {name}")
    
    print()
    passed = sum(1 for _, result in results if result)
    total = len(results)
    print(f"æ€»è®¡: {passed}/{total} é€šè¿‡")
    print()
    
    if chunks:
        print("=" * 60)
        print("ä¸‹ä¸€æ­¥")
        print("=" * 60)
        print()
        print("å¦‚æœçœ‹åˆ°æœªå‘é‡åŒ–çš„åˆ†å—ï¼Œå¯ä»¥è¿è¡Œå®Œæ•´çš„å‘é‡åŒ–æµ‹è¯•ï¼š")
        print("  python tests/test_vectorize_job.py")
        print()
        print("æˆ–è€…åœ¨ Dagster UI ä¸­è¿è¡Œå‘é‡åŒ–ä½œä¸šï¼š")
        print("  - ä½œä¸šåç§°: vectorize_documents_job")
        print("  - ä¼ æ„Ÿå™¨: manual_trigger_vectorize_sensor")
        print()


if __name__ == "__main__":
    main()
