#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æŸ¥çœ‹ document_chunks è¡¨ç»Ÿè®¡ä¿¡æ¯
æ˜¾ç¤ºåˆ†å—æ•°é‡ã€å‘é‡åŒ–çŠ¶æ€ç­‰
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.storage.metadata.postgres_client import get_postgres_client
from src.storage.metadata.models import DocumentChunk, Document
from sqlalchemy import func


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("DocumentChunks è¡¨ç»Ÿè®¡ä¿¡æ¯")
    print("=" * 60)
    print()
    
    pg_client = get_postgres_client()
    
    try:
        with pg_client.get_session() as session:
            # æ€»åˆ†å—æ•°
            total_chunks = session.query(func.count(DocumentChunk.id)).scalar()
            print(f"ğŸ“Š æ€»åˆ†å—æ•°: {total_chunks:,}")
            print()
            
            # æœªå‘é‡åŒ–åˆ†å—æ•°
            unvectorized = session.query(func.count(DocumentChunk.id)).filter(
                DocumentChunk.vector_id.is_(None)
            ).scalar()
            print(f"â° æœªå‘é‡åŒ–åˆ†å—æ•°: {unvectorized:,}")
            
            # å·²å‘é‡åŒ–åˆ†å—æ•°
            vectorized = session.query(func.count(DocumentChunk.id)).filter(
                DocumentChunk.vector_id.isnot(None)
            ).scalar()
            print(f"âœ… å·²å‘é‡åŒ–åˆ†å—æ•°: {vectorized:,}")
            
            if total_chunks > 0:
                vectorized_rate = (vectorized / total_chunks) * 100
                print(f"ğŸ“ˆ å‘é‡åŒ–ç‡: {vectorized_rate:.2f}%")
            print()
            
            # æŒ‰æ–‡æ¡£ç»Ÿè®¡
            print("=" * 60)
            print("æŒ‰æ–‡æ¡£ç»Ÿè®¡")
            print("=" * 60)
            print()
            
            # æœ‰åˆ†å—çš„æ–‡æ¡£æ•°
            docs_with_chunks = session.query(func.count(func.distinct(DocumentChunk.document_id))).scalar()
            print(f"ğŸ“„ æœ‰åˆ†å—çš„æ–‡æ¡£æ•°: {docs_with_chunks:,}")
            
            # å¹³å‡æ¯ä¸ªæ–‡æ¡£çš„åˆ†å—æ•°
            if docs_with_chunks > 0:
                avg_chunks = total_chunks / docs_with_chunks
                print(f"ğŸ“Š å¹³å‡æ¯ä¸ªæ–‡æ¡£çš„åˆ†å—æ•°: {avg_chunks:.2f}")
            print()
            
            # æŒ‰å¸‚åœºç»Ÿè®¡
            print("=" * 60)
            print("æŒ‰å¸‚åœºç»Ÿè®¡")
            print("=" * 60)
            print()
            
            market_stats = session.query(
                Document.market,
                func.count(DocumentChunk.id).label('chunk_count')
            ).join(
                DocumentChunk, Document.id == DocumentChunk.document_id
            ).group_by(Document.market).all()
            
            for market, count in market_stats:
                print(f"  {market}: {count:,} ä¸ªåˆ†å—")
            print()
            
            # æŒ‰æ–‡æ¡£ç±»å‹ç»Ÿè®¡
            print("=" * 60)
            print("æŒ‰æ–‡æ¡£ç±»å‹ç»Ÿè®¡")
            print("=" * 60)
            print()
            
            doc_type_stats = session.query(
                Document.doc_type,
                func.count(DocumentChunk.id).label('chunk_count')
            ).join(
                DocumentChunk, Document.id == DocumentChunk.document_id
            ).group_by(Document.doc_type).all()
            
            for doc_type, count in doc_type_stats:
                print(f"  {doc_type}: {count:,} ä¸ªåˆ†å—")
            print()
            
            # å‘é‡åŒ–çŠ¶æ€è¯¦æƒ…
            if vectorized > 0:
                print("=" * 60)
                print("å‘é‡åŒ–è¯¦æƒ…")
                print("=" * 60)
                print()
                
                # æŒ‰æ¨¡å‹ç»Ÿè®¡
                model_stats = session.query(
                    DocumentChunk.embedding_model,
                    func.count(DocumentChunk.id).label('count')
                ).filter(
                    DocumentChunk.embedding_model.isnot(None)
                ).group_by(DocumentChunk.embedding_model).all()
                
                print("ä½¿ç”¨çš„ Embedding æ¨¡å‹:")
                for model, count in model_stats:
                    print(f"  {model}: {count:,} ä¸ªåˆ†å—")
                print()
            
            # æœ€è¿‘å‘é‡åŒ–çš„åˆ†å—
            if vectorized > 0:
                print("=" * 60)
                print("æœ€è¿‘å‘é‡åŒ–çš„åˆ†å—ï¼ˆå‰5ä¸ªï¼‰")
                print("=" * 60)
                print()
                
                recent_chunks = session.query(DocumentChunk).filter(
                    DocumentChunk.vectorized_at.isnot(None)
                ).order_by(
                    DocumentChunk.vectorized_at.desc()
                ).limit(5).all()
                
                for i, chunk in enumerate(recent_chunks, 1):
                    doc = session.query(Document).filter(
                        Document.id == chunk.document_id
                    ).first()
                    print(f"{i}. chunk_id={chunk.id}")
                    print(f"   document_id={chunk.document_id}")
                    print(f"   stock_code={doc.stock_code if doc else 'N/A'}")
                    print(f"   vector_id={chunk.vector_id}")
                    print(f"   embedding_model={chunk.embedding_model}")
                    print(f"   vectorized_at={chunk.vectorized_at}")
                    print()
            
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    
    print("=" * 60)
    print("æŸ¥è¯¢å®Œæˆ")
    print("=" * 60)


if __name__ == "__main__":
    main()
