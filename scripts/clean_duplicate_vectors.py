#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¸…ç† Milvus ä¸­çš„é‡å¤å‘é‡
å½“ä½¿ç”¨ force_revectorize æ—¶ï¼Œå¦‚æœæ²¡æœ‰åˆ é™¤æ—§å‘é‡ï¼Œä¼šå¯¼è‡´åŒä¸€ä¸ª chunk_id æœ‰å¤šä¸ªå‘é‡
"""

import sys
from pathlib import Path
from typing import Dict, List, Set
from collections import defaultdict

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.storage.vector.milvus_client import get_milvus_client
from src.storage.metadata.postgres_client import get_postgres_client
from src.storage.metadata.models import DocumentChunk
from src.common.constants import MilvusCollection
from src.common.logger import get_logger

logger = get_logger(__name__)


def get_valid_vector_ids_from_postgres() -> Dict[str, str]:
    """
    ä» PostgreSQL è·å–æ‰€æœ‰å·²å‘é‡åŒ–çš„ chunk_id åŠå…¶å¯¹åº”çš„ vector_id
    
    Returns:
        å­—å…¸ {chunk_id: vector_id}
    """
    logger.info("æ­£åœ¨ä» PostgreSQL è·å–æœ‰æ•ˆçš„å‘é‡æ˜ å°„...")
    
    pg_client = get_postgres_client()
    chunk_to_vector = {}
    
    with pg_client.get_session() as session:
        chunks = session.query(
            DocumentChunk.id,
            DocumentChunk.vector_id
        ).filter(
            DocumentChunk.vector_id.isnot(None)
        ).all()
        
        for chunk in chunks:
            chunk_to_vector[str(chunk.id)] = str(chunk.vector_id)
    
    logger.info(f"ä» PostgreSQL è·å–åˆ° {len(chunk_to_vector)} ä¸ªæœ‰æ•ˆçš„å‘é‡æ˜ å°„")
    return chunk_to_vector


def get_all_vectors_from_milvus(collection_name: str) -> List[dict]:
    """
    ä» Milvus è·å–æ‰€æœ‰å‘é‡
    
    Args:
        collection_name: Collection åç§°
        
    Returns:
        åŒ…å« id, chunk_id çš„å­—å…¸åˆ—è¡¨
    """
    logger.info(f"æ­£åœ¨ä» Milvus Collection '{collection_name}' è·å–æ‰€æœ‰å‘é‡...")
    
    milvus_client = get_milvus_client()
    collection = milvus_client.get_collection(collection_name)
    
    if not collection:
        logger.error(f"Collection ä¸å­˜åœ¨: {collection_name}")
        return []
    
    # åŠ è½½ collection
    try:
        collection.load()
    except Exception as e:
        logger.warning(f"åŠ è½½ Collection å¤±è´¥: {e}")
    
    # æŸ¥è¯¢æ‰€æœ‰å‘é‡
    all_vectors = []
    batch_size = 1000
    offset = 0
    
    logger.info("å¼€å§‹åˆ†æ‰¹æŸ¥è¯¢å‘é‡...")
    
    while True:
        try:
            results = collection.query(
                expr="id >= 0",
                output_fields=["id", "chunk_id"],
                limit=batch_size,
                offset=offset
            )
            
            if not results:
                break
            
            all_vectors.extend(results)
            offset += len(results)
            
            logger.info(f"å·²æŸ¥è¯¢ {offset} ä¸ªå‘é‡...")
            
            if len(results) < batch_size:
                break
                
        except Exception as e:
            logger.error(f"æŸ¥è¯¢ Milvus å¤±è´¥ (offset={offset}): {e}")
            break
    
    logger.info(f"ä» Milvus è·å–åˆ° {len(all_vectors)} ä¸ªå‘é‡")
    return all_vectors


def find_duplicate_and_invalid_vectors(
    milvus_vectors: List[dict],
    postgres_mapping: Dict[str, str]
) -> tuple[List[int], Dict[str, List[dict]]]:
    """
    æŸ¥æ‰¾é‡å¤å’Œæ— æ•ˆçš„å‘é‡
    
    Args:
        milvus_vectors: Milvus ä¸­çš„æ‰€æœ‰å‘é‡
        postgres_mapping: PostgreSQL ä¸­çš„ chunk_id -> vector_id æ˜ å°„
        
    Returns:
        (è¦åˆ é™¤çš„ milvus_id åˆ—è¡¨, é‡å¤å‘é‡çš„åˆ†ç»„)
    """
    logger.info("æ­£åœ¨åˆ†æå‘é‡é‡å¤æƒ…å†µ...")
    
    # æŒ‰ chunk_id åˆ†ç»„
    chunk_groups = defaultdict(list)
    for vector in milvus_vectors:
        chunk_id = vector.get("chunk_id")
        milvus_id = vector.get("id")
        chunk_groups[chunk_id].append({
            "milvus_id": milvus_id,
            "chunk_id": chunk_id
        })
    
    # ç»Ÿè®¡
    total_chunks = len(chunk_groups)
    duplicate_chunks = sum(1 for vectors in chunk_groups.values() if len(vectors) > 1)
    
    logger.info(f"ç»Ÿè®¡:")
    logger.info(f"  Milvus ä¸­çš„å‘é‡æ€»æ•°: {len(milvus_vectors):,}")
    logger.info(f"  å”¯ä¸€çš„ chunk_id æ•°é‡: {total_chunks:,}")
    logger.info(f"  æœ‰é‡å¤å‘é‡çš„ chunk æ•°é‡: {duplicate_chunks:,}")
    
    # æŸ¥æ‰¾éœ€è¦åˆ é™¤çš„å‘é‡
    to_delete = []
    duplicate_details = {}
    
    for chunk_id, vectors in chunk_groups.items():
        if len(vectors) > 1:
            # æœ‰é‡å¤ï¼Œè®°å½•è¯¦æƒ…
            duplicate_details[chunk_id] = vectors
            
            # è·å– PostgreSQL ä¸­è®°å½•çš„æœ‰æ•ˆ vector_id
            valid_vector_id = postgres_mapping.get(chunk_id)
            
            if valid_vector_id:
                # ä¿ç•™ PostgreSQL ä¸­è®°å½•çš„ vector_idï¼Œåˆ é™¤å…¶ä»–çš„
                for vector in vectors:
                    if str(vector["milvus_id"]) != valid_vector_id:
                        to_delete.append(vector["milvus_id"])
            else:
                # PostgreSQL ä¸­æ²¡æœ‰è®°å½•ï¼Œä¿ç•™æœ€æ–°çš„ï¼ˆID æœ€å¤§çš„ï¼‰ï¼Œåˆ é™¤å…¶ä»–çš„
                sorted_vectors = sorted(vectors, key=lambda x: x["milvus_id"], reverse=True)
                for vector in sorted_vectors[1:]:  # è·³è¿‡ç¬¬ä¸€ä¸ªï¼ˆæœ€æ–°çš„ï¼‰
                    to_delete.append(vector["milvus_id"])
    
    logger.info(f"å‘ç° {len(to_delete)} ä¸ªé‡å¤å‘é‡éœ€è¦åˆ é™¤")
    
    return to_delete, duplicate_details


def delete_vectors_by_ids(
    collection_name: str,
    milvus_ids: List[int],
    batch_size: int = 100,
    dry_run: bool = True
) -> int:
    """
    æ ¹æ® Milvus ID åˆ é™¤å‘é‡
    
    Args:
        collection_name: Collection åç§°
        milvus_ids: è¦åˆ é™¤çš„ Milvus ID åˆ—è¡¨
        batch_size: æ‰¹é‡åˆ é™¤çš„å¤§å°
        dry_run: æ˜¯å¦ä¸ºè¯•è¿è¡Œ
        
    Returns:
        åˆ é™¤çš„å‘é‡æ•°é‡
    """
    if not milvus_ids:
        logger.info("æ²¡æœ‰å‘é‡éœ€è¦åˆ é™¤")
        return 0
    
    if dry_run:
        logger.warning("=" * 80)
        logger.warning("ğŸ” DRY RUN æ¨¡å¼ - ä¸ä¼šå®é™…åˆ é™¤å‘é‡")
        logger.warning("=" * 80)
        logger.warning(f"å°†è¦åˆ é™¤ {len(milvus_ids)} ä¸ªé‡å¤å‘é‡")
        return 0
    
    logger.warning("=" * 80)
    logger.warning("âš ï¸  å³å°†åˆ é™¤é‡å¤å‘é‡ï¼")
    logger.warning("=" * 80)
    logger.warning(f"Collection: {collection_name}")
    logger.warning(f"è¦åˆ é™¤çš„å‘é‡æ•°é‡: {len(milvus_ids)}")
    logger.warning("=" * 80)
    
    # ç¡®è®¤åˆ é™¤
    try:
        confirmation = input("ç¡®è®¤åˆ é™¤ï¼Ÿè¾“å…¥ 'yes' ç»§ç»­: ")
        if confirmation.lower() != 'yes':
            logger.info("æ“ä½œå·²å–æ¶ˆ")
            return 0
    except Exception:
        logger.error("æ— æ³•è·å–ç”¨æˆ·è¾“å…¥ï¼Œæ“ä½œå–æ¶ˆ")
        return 0
    
    milvus_client = get_milvus_client()
    collection = milvus_client.get_collection(collection_name)
    
    if not collection:
        logger.error(f"Collection ä¸å­˜åœ¨: {collection_name}")
        return 0
    
    deleted_count = 0
    
    # åˆ†æ‰¹åˆ é™¤
    for i in range(0, len(milvus_ids), batch_size):
        batch = milvus_ids[i:i + batch_size]
        
        try:
            # æ„å»ºåˆ é™¤è¡¨è¾¾å¼
            ids_str = ", ".join(str(id) for id in batch)
            expr = f"id in [{ids_str}]"
            
            # æ‰§è¡Œåˆ é™¤
            collection.delete(expr)
            collection.flush()
            
            deleted_count += len(batch)
            logger.info(f"å·²åˆ é™¤ {deleted_count}/{len(milvus_ids)} ä¸ªå‘é‡")
            
        except Exception as e:
            logger.error(f"åˆ é™¤å‘é‡å¤±è´¥ (batch {i//batch_size + 1}): {e}")
    
    logger.info("=" * 80)
    logger.info(f"âœ“ æˆåŠŸåˆ é™¤ {deleted_count} ä¸ªé‡å¤å‘é‡")
    logger.info("=" * 80)
    
    return deleted_count


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="æ¸…ç† Milvus ä¸­çš„é‡å¤å‘é‡")
    parser.add_argument(
        "--dry-run",
        action="store_true",
        default=True,
        help="è¯•è¿è¡Œæ¨¡å¼ï¼ˆä¸å®é™…åˆ é™¤ï¼Œé»˜è®¤å¯ç”¨ï¼‰"
    )
    parser.add_argument(
        "--force",
        action="store_true",
        help="å¼ºåˆ¶æ‰§è¡Œåˆ é™¤ï¼ˆç¦ç”¨è¯•è¿è¡Œï¼‰"
    )
    parser.add_argument(
        "--collection",
        default=MilvusCollection.DOCUMENTS,
        help=f"Collection åç§°ï¼ˆé»˜è®¤: {MilvusCollection.DOCUMENTS}ï¼‰"
    )
    parser.add_argument(
        "--batch-size",
        type=int,
        default=100,
        help="æ‰¹é‡åˆ é™¤çš„å¤§å°ï¼ˆé»˜è®¤: 100ï¼‰"
    )
    parser.add_argument(
        "--show-details",
        action="store_true",
        help="æ˜¾ç¤ºé‡å¤å‘é‡çš„è¯¦ç»†ä¿¡æ¯"
    )
    
    args = parser.parse_args()
    
    # ç¡®å®šæ˜¯å¦ä¸ºè¯•è¿è¡Œ
    dry_run = not args.force
    
    try:
        logger.info("=" * 80)
        logger.info("æ¸…ç† Milvus é‡å¤å‘é‡å·¥å…·")
        logger.info("=" * 80)
        logger.info(f"Collection: {args.collection}")
        logger.info(f"æ‰¹é‡å¤§å°: {args.batch_size}")
        logger.info(f"æ¨¡å¼: {'DRY RUN (è¯•è¿è¡Œ)' if dry_run else 'å®é™…åˆ é™¤'}")
        logger.info("=" * 80)
        logger.info("")
        
        # 1. ä» PostgreSQL è·å–æœ‰æ•ˆçš„å‘é‡æ˜ å°„
        postgres_mapping = get_valid_vector_ids_from_postgres()
        
        # 2. ä» Milvus è·å–æ‰€æœ‰å‘é‡
        milvus_vectors = get_all_vectors_from_milvus(args.collection)
        
        if not milvus_vectors:
            logger.warning("Milvus ä¸­æ²¡æœ‰å‘é‡")
            return
        
        # 3. æŸ¥æ‰¾é‡å¤å’Œæ— æ•ˆçš„å‘é‡
        to_delete, duplicate_details = find_duplicate_and_invalid_vectors(
            milvus_vectors,
            postgres_mapping
        )
        
        # 4. æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        if args.show_details and duplicate_details:
            logger.info("")
            logger.info("=" * 80)
            logger.info(f"é‡å¤å‘é‡è¯¦æƒ…ï¼ˆå‰ 20 ä¸ªï¼‰:")
            logger.info("=" * 80)
            
            for i, (chunk_id, vectors) in enumerate(list(duplicate_details.items())[:20], 1):
                valid_vector_id = postgres_mapping.get(chunk_id)
                logger.info(f"\n{i}. Chunk ID: {chunk_id}")
                logger.info(f"   é‡å¤æ•°é‡: {len(vectors)}")
                logger.info(f"   PostgreSQL è®°å½•çš„ vector_id: {valid_vector_id or '(æ— )'}")
                logger.info(f"   Milvus ä¸­çš„å‘é‡ IDs:")
                for vector in vectors:
                    milvus_id = vector["milvus_id"]
                    is_valid = str(milvus_id) == valid_vector_id
                    status = "âœ“ ä¿ç•™" if is_valid else "âœ— åˆ é™¤"
                    logger.info(f"     - {milvus_id} {status}")
        
        # 5. ç»Ÿè®¡ä¿¡æ¯
        logger.info("")
        logger.info("=" * 80)
        logger.info("ç»Ÿè®¡ä¿¡æ¯:")
        logger.info(f"  Milvus ä¸­çš„å‘é‡æ€»æ•°: {len(milvus_vectors):,}")
        logger.info(f"  PostgreSQL ä¸­å·²å‘é‡åŒ–çš„åˆ†å—æ•°: {len(postgres_mapping):,}")
        logger.info(f"  é‡å¤å‘é‡æ•°é‡: {len(to_delete):,}")
        logger.info(f"  åˆ é™¤åé¢„è®¡å‘é‡æ•°: {len(milvus_vectors) - len(to_delete):,}")
        logger.info("=" * 80)
        logger.info("")
        
        # 6. åˆ é™¤é‡å¤å‘é‡
        deleted_count = delete_vectors_by_ids(
            collection_name=args.collection,
            milvus_ids=to_delete,
            batch_size=args.batch_size,
            dry_run=dry_run
        )
        
        if dry_run and to_delete:
            logger.info("")
            logger.info("=" * 80)
            logger.info("ğŸ’¡ æç¤º:")
            logger.info("  è¿™æ˜¯è¯•è¿è¡Œæ¨¡å¼ï¼Œæ²¡æœ‰å®é™…åˆ é™¤å‘é‡")
            logger.info("  è¦æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯ï¼Œè¯·è¿è¡Œ:")
            logger.info(f"  python {__file__} --dry-run --show-details")
            logger.info("")
            logger.info("  è¦æ‰§è¡Œå®é™…åˆ é™¤ï¼Œè¯·è¿è¡Œ:")
            logger.info(f"  python {__file__} --force")
            logger.info("=" * 80)
        elif deleted_count > 0:
            logger.info("")
            logger.info("å»ºè®®:")
            logger.info("  åˆ é™¤å®Œæˆåï¼Œå»ºè®®é‡æ–°æ£€æŸ¥å‘é‡æ•°é‡:")
            logger.info("  python scripts/check_milvus_direct.sh")
            logger.info("  python scripts/check_vectorized_chunks.py")
        
    except KeyboardInterrupt:
        logger.warning("\næ“ä½œå·²è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        logger.error(f"æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        sys.exit(1)


if __name__ == "__main__":
    main()
