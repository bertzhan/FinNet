#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®åº“ Schema è¿ç§»è„šæœ¬
æ‰§è¡Œä»¥ä¸‹å˜æ›´ï¼š
1. åˆ é™¤ document_chunks.vector_id å­—æ®µ
2. å°† listed_companies.code è®¾ä¸ºä¸»é”®ï¼Œåˆ é™¤ id å­—æ®µ
"""

import sys
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.storage.metadata.postgres_client import get_postgres_client
from src.common.logger import get_logger
from sqlalchemy import text

logger = get_logger(__name__)


def check_vector_id_migration(session):
    """æ£€æŸ¥ vector_id è¿ç§»çŠ¶æ€"""
    logger.info("=" * 80)
    logger.info("æ£€æŸ¥ document_chunks.vector_id è¿ç§»çŠ¶æ€")
    logger.info("=" * 80)
    
    # æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨
    result = session.execute(text("""
        SELECT column_name 
        FROM information_schema.columns 
        WHERE table_name = 'document_chunks' 
          AND column_name = 'vector_id'
    """)).fetchone()
    
    has_vector_id = result is not None
    
    if has_vector_id:
        # æ£€æŸ¥æ•°æ®çŠ¶æ€
        result = session.execute(text("""
            SELECT 
                COUNT(*) as total,
                COUNT(vector_id) as has_vector_id,
                COUNT(vectorized_at) as has_vectorized_at
            FROM document_chunks
        """)).fetchone()
        
        logger.info(f"å½“å‰çŠ¶æ€:")
        logger.info(f"  æ€»åˆ†å—æ•°: {result[0]:,}")
        logger.info(f"  æœ‰ vector_id: {result[1]:,}")
        logger.info(f"  æœ‰ vectorized_at: {result[2]:,}")
        
        # æ£€æŸ¥éœ€è¦è¿ç§»çš„è®°å½•
        result = session.execute(text("""
            SELECT COUNT(*) 
            FROM document_chunks 
            WHERE vector_id IS NOT NULL AND vectorized_at IS NULL
        """)).fetchone()
        
        need_migration = result[0] if result else 0
        logger.info(f"  éœ€è¦è¿ç§»çš„è®°å½•: {need_migration:,}")
        
        return True, need_migration
    else:
        logger.info("âœ“ vector_id å­—æ®µå·²ä¸å­˜åœ¨ï¼Œæ— éœ€è¿ç§»")
        return False, 0


def migrate_vector_id(session, dry_run=True):
    """è¿ç§» vector_id æ•°æ®å¹¶åˆ é™¤å­—æ®µ"""
    logger.info("=" * 80)
    logger.info("è¿ç§» document_chunks.vector_id")
    logger.info("=" * 80)
    
    has_vector_id, need_migration = check_vector_id_migration(session)
    
    if not has_vector_id:
        logger.info("âœ“ vector_id å­—æ®µå·²ä¸å­˜åœ¨ï¼Œè·³è¿‡")
        return True
    
    if need_migration > 0:
        if dry_run:
            logger.info(f"ğŸ” DRY RUN: å°†è¿ç§» {need_migration:,} æ¡è®°å½•")
            logger.info("  å®é™…æ‰§è¡Œæ—¶ä¼šå°† vectorized_at è®¾ç½®ä¸ºå½“å‰æ—¶é—´")
            return False
        else:
            logger.info(f"æ­£åœ¨è¿ç§» {need_migration:,} æ¡è®°å½•...")
            session.execute(text("""
                UPDATE document_chunks 
                SET vectorized_at = COALESCE(vectorized_at, NOW())
                WHERE vector_id IS NOT NULL AND vectorized_at IS NULL
            """))
            session.commit()
            logger.info("âœ“ æ•°æ®è¿ç§»å®Œæˆ")
    
    # åˆ é™¤ vector_id åˆ—
    if dry_run:
        logger.info("ğŸ” DRY RUN: å°†åˆ é™¤ vector_id åˆ—")
        return False
    else:
        logger.info("æ­£åœ¨åˆ é™¤ vector_id åˆ—...")
        try:
            session.execute(text("ALTER TABLE document_chunks DROP COLUMN vector_id"))
            session.commit()
            logger.info("âœ“ vector_id åˆ—å·²åˆ é™¤")
            return True
        except Exception as e:
            logger.error(f"åˆ é™¤ vector_id åˆ—å¤±è´¥: {e}")
            session.rollback()
            return False


def check_company_code_migration(session):
    """æ£€æŸ¥ listed_companies.code ä¸»é”®è¿ç§»çŠ¶æ€"""
    logger.info("=" * 80)
    logger.info("æ£€æŸ¥ listed_companies.code ä¸»é”®è¿ç§»çŠ¶æ€")
    logger.info("=" * 80)
    
    # æ£€æŸ¥ä¸»é”®
    result = session.execute(text("""
        SELECT constraint_name, constraint_type
        FROM information_schema.table_constraints
        WHERE table_name = 'listed_companies'
          AND constraint_type = 'PRIMARY KEY'
    """)).fetchall()
    
    # æ£€æŸ¥åˆ—
    columns = session.execute(text("""
        SELECT column_name, data_type, is_nullable
        FROM information_schema.columns
        WHERE table_name = 'listed_companies'
        ORDER BY ordinal_position
    """)).fetchall()
    
    has_id_column = any(col[0] == 'id' for col in columns)
    code_is_pk = any('code' in str(constraint) for constraint in result)
    
    logger.info(f"å½“å‰çŠ¶æ€:")
    logger.info(f"  æœ‰ id åˆ—: {has_id_column}")
    logger.info(f"  code æ˜¯ä¸»é”®: {code_is_pk}")
    
    if has_id_column:
        # æ£€æŸ¥æ•°æ®
        result = session.execute(text("""
            SELECT 
                COUNT(*) as total,
                COUNT(DISTINCT code) as unique_codes
            FROM listed_companies
        """)).fetchone()
        
        logger.info(f"  æ€»è®°å½•æ•°: {result[0]:,}")
        logger.info(f"  å”¯ä¸€ code æ•°: {result[1]:,}")
        
        if result[0] != result[1]:
            # æ£€æŸ¥é‡å¤
            result = session.execute(text("""
                SELECT code, COUNT(*) as count
                FROM listed_companies
                GROUP BY code
                HAVING COUNT(*) > 1
                LIMIT 10
            """)).fetchall()
            
            logger.warning(f"âš ï¸  å‘ç°é‡å¤çš„ code:")
            for code, count in result:
                logger.warning(f"    {code}: {count} æ¡è®°å½•")
        
        return True, result[0] != result[1] if result else False
    else:
        logger.info("âœ“ id åˆ—å·²ä¸å­˜åœ¨ï¼Œcode å·²è®¾ä¸ºä¸»é”®")
        return False, False


def migrate_company_code_pk(session, dry_run=True):
    """å°† listed_companies.code è®¾ä¸ºä¸»é”®"""
    logger.info("=" * 80)
    logger.info("è¿ç§» listed_companies.code ä¸»é”®")
    logger.info("=" * 80)
    
    has_id_column, has_duplicates = check_company_code_migration(session)
    
    if not has_id_column:
        logger.info("âœ“ code å·²è®¾ä¸ºä¸»é”®ï¼Œè·³è¿‡")
        return True
    
    if has_duplicates:
        logger.error("âŒ å‘ç°é‡å¤çš„ codeï¼Œè¯·å…ˆæ¸…ç†é‡å¤æ•°æ®")
        logger.error("   å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ SQL æ¸…ç†ï¼ˆä¿ç•™æœ€æ–°çš„è®°å½•ï¼‰:")
        logger.error("""
            DELETE FROM listed_companies
            WHERE id NOT IN (
                SELECT MAX(id)
                FROM listed_companies
                GROUP BY code
            );
        """)
        return False
    
    if dry_run:
        logger.info("ğŸ” DRY RUN: å°†æ‰§è¡Œä»¥ä¸‹æ“ä½œ:")
        logger.info("  1. åˆ é™¤ idx_code ç´¢å¼•ï¼ˆå¦‚æœå­˜åœ¨ï¼‰")
        logger.info("  2. åˆ é™¤ id åˆ—")
        logger.info("  3. è®¾ç½® code ä¸ºä¸»é”®")
        return False
    else:
        try:
            # åˆ é™¤ç´¢å¼•ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            logger.info("æ­£åœ¨åˆ é™¤ idx_code ç´¢å¼•...")
            try:
                session.execute(text("DROP INDEX IF EXISTS idx_code"))
                session.commit()
            except Exception as e:
                logger.warning(f"åˆ é™¤ç´¢å¼•å¤±è´¥ï¼ˆå¯èƒ½ä¸å­˜åœ¨ï¼‰: {e}")
            
            # åˆ é™¤ id åˆ—å¹¶è®¾ç½® code ä¸ºä¸»é”®
            logger.info("æ­£åœ¨åˆ é™¤ id åˆ—å¹¶è®¾ç½® code ä¸ºä¸»é”®...")
            session.execute(text("""
                ALTER TABLE listed_companies 
                DROP COLUMN id,
                ADD PRIMARY KEY (code)
            """))
            session.commit()
            logger.info("âœ“ code å·²è®¾ä¸ºä¸»é”®")
            return True
        except Exception as e:
            logger.error(f"è¿ç§»å¤±è´¥: {e}")
            session.rollback()
            return False


def verify_migration(session):
    """éªŒè¯è¿ç§»ç»“æœ"""
    logger.info("=" * 80)
    logger.info("éªŒè¯è¿ç§»ç»“æœ")
    logger.info("=" * 80)
    
    # éªŒè¯ vector_id
    result = session.execute(text("""
        SELECT column_name 
        FROM information_schema.columns 
        WHERE table_name = 'document_chunks' 
          AND column_name = 'vector_id'
    """)).fetchone()
    
    if result:
        logger.warning("âš ï¸  document_chunks.vector_id ä»ç„¶å­˜åœ¨")
    else:
        logger.info("âœ“ document_chunks.vector_id å·²åˆ é™¤")
    
    # éªŒè¯ listed_companies
    result = session.execute(text("""
        SELECT column_name 
        FROM information_schema.columns 
        WHERE table_name = 'listed_companies' 
          AND column_name = 'id'
    """)).fetchone()
    
    if result:
        logger.warning("âš ï¸  listed_companies.id ä»ç„¶å­˜åœ¨")
    else:
        logger.info("âœ“ listed_companies.id å·²åˆ é™¤")
    
    result = session.execute(text("""
        SELECT constraint_name, constraint_type
        FROM information_schema.table_constraints
        WHERE table_name = 'listed_companies'
          AND constraint_type = 'PRIMARY KEY'
    """)).fetchone()
    
    if result:
        logger.info(f"âœ“ listed_companies ä¸»é”®: {result[0]}")
    else:
        logger.warning("âš ï¸  listed_companies æ²¡æœ‰ä¸»é”®")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="æ•°æ®åº“ Schema è¿ç§»å·¥å…·")
    parser.add_argument(
        "--dry-run",
        action="store_true",
        default=True,
        help="è¯•è¿è¡Œæ¨¡å¼ï¼ˆä¸å®é™…æ‰§è¡Œï¼Œé»˜è®¤å¯ç”¨ï¼‰"
    )
    parser.add_argument(
        "--force",
        action="store_true",
        help="å¼ºåˆ¶æ‰§è¡Œè¿ç§»ï¼ˆç¦ç”¨è¯•è¿è¡Œï¼‰"
    )
    parser.add_argument(
        "--skip-vector-id",
        action="store_true",
        help="è·³è¿‡ vector_id è¿ç§»"
    )
    parser.add_argument(
        "--skip-company-pk",
        action="store_true",
        help="è·³è¿‡ company code ä¸»é”®è¿ç§»"
    )
    
    args = parser.parse_args()
    
    dry_run = not args.force
    
    try:
        logger.info("=" * 80)
        logger.info("æ•°æ®åº“ Schema è¿ç§»å·¥å…·")
        logger.info("=" * 80)
        logger.info(f"æ¨¡å¼: {'DRY RUN (è¯•è¿è¡Œ)' if dry_run else 'å®é™…æ‰§è¡Œ'}")
        logger.info("=" * 80)
        logger.info("")
        
        pg_client = get_postgres_client()
        
        with pg_client.get_session() as session:
            # 1. è¿ç§» vector_id
            if not args.skip_vector_id:
                success = migrate_vector_id(session, dry_run=dry_run)
                if not success and not dry_run:
                    logger.error("vector_id è¿ç§»å¤±è´¥")
                    return 1
                logger.info("")
            
            # 2. è¿ç§» company code ä¸»é”®
            if not args.skip_company_pk:
                success = migrate_company_code_pk(session, dry_run=dry_run)
                if not success and not dry_run:
                    logger.error("company code ä¸»é”®è¿ç§»å¤±è´¥")
                    return 1
                logger.info("")
            
            # 3. éªŒè¯
            verify_migration(session)
        
        if dry_run:
            logger.info("")
            logger.info("=" * 80)
            logger.info("ğŸ’¡ æç¤º:")
            logger.info("  è¿™æ˜¯è¯•è¿è¡Œæ¨¡å¼ï¼Œæ²¡æœ‰å®é™…æ‰§è¡Œè¿ç§»")
            logger.info("  è¦æ‰§è¡Œå®é™…è¿ç§»ï¼Œè¯·è¿è¡Œ:")
            logger.info("    python scripts/migrate_database_schema.py --force")
            logger.info("=" * 80)
        else:
            logger.info("")
            logger.info("=" * 80)
            logger.info("âœ… è¿ç§»å®Œæˆï¼")
            logger.info("=" * 80)
        
        return 0
        
    except KeyboardInterrupt:
        logger.warning("\næ“ä½œå·²è¢«ç”¨æˆ·ä¸­æ–­")
        return 1
    except Exception as e:
        logger.error(f"è¿ç§»å¤±è´¥: {e}", exc_info=True)
        return 1


if __name__ == "__main__":
    sys.exit(main())
