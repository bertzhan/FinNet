#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¸…ç† Milvus ä¸­çš„å­¤ç«‹å‘é‡
å­¤ç«‹å‘é‡æ˜¯æŒ‡ï¼šåœ¨ Milvus ä¸­å­˜åœ¨ï¼Œä½†åœ¨ PostgreSQL å…ƒæ•°æ®ä¸­æ²¡æœ‰å¯¹åº”è®°å½•çš„å‘é‡
"""

import sys
from pathlib import Path
from typing import Set, List
import uuid

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.storage.vector.milvus_client import get_milvus_client
from src.storage.metadata.postgres_client import get_postgres_client
from src.storage.metadata.models import DocumentChunk
from src.common.constants import MilvusCollection
from src.common.logger import get_logger

logger = get_logger(__name__)


def get_all_chunk_ids_from_postgres() -> Set[str]:
    """
    ä» PostgreSQL è·å–æ‰€æœ‰å·²å‘é‡åŒ–çš„ chunk_id
    
    Returns:
        chunk_id çš„é›†åˆ
    """
    logger.info("æ­£åœ¨ä» PostgreSQL è·å–æ‰€æœ‰å·²å‘é‡åŒ–çš„ chunk_id...")
    
    pg_client = get_postgres_client()
    chunk_ids = set()
    
    with pg_client.get_session() as session:
        # æŸ¥è¯¢æ‰€æœ‰æœ‰ vectorized_at çš„åˆ†å—ï¼ˆè¡¨ç¤ºå·²å‘é‡åŒ–ï¼‰
        chunks = session.query(DocumentChunk.id).filter(
            DocumentChunk.vectorized_at.isnot(None)
        ).all()
        
        for chunk in chunks:
            chunk_ids.add(str(chunk.id))
    
    logger.info(f"ä» PostgreSQL è·å–åˆ° {len(chunk_ids)} ä¸ªå·²å‘é‡åŒ–çš„ chunk_id")
    return chunk_ids


def get_all_chunk_ids_from_milvus(collection_name: str) -> List[dict]:
    """
    ä» Milvus è·å–æ‰€æœ‰å‘é‡çš„ chunk_id
    
    Args:
        collection_name: Collection åç§°
        
    Returns:
        åŒ…å« chunk_id çš„å­—å…¸åˆ—è¡¨
    """
    logger.info(f"æ­£åœ¨ä» Milvus Collection '{collection_name}' è·å–æ‰€æœ‰å‘é‡...")
    
    milvus_client = get_milvus_client()
    collection = milvus_client.get_collection(collection_name)
    
    if not collection:
        logger.error(f"Collection ä¸å­˜åœ¨: {collection_name}")
        return []
    
    # åŠ è½½ collection
    try:
        collection.load()
    except Exception as e:
        logger.warning(f"åŠ è½½ Collection å¤±è´¥: {e}")
    
    # æŸ¥è¯¢æ‰€æœ‰å‘é‡çš„ chunk_id
    # ä½¿ç”¨åˆ†é¡µæŸ¥è¯¢ï¼Œé¿å…ä¸€æ¬¡æ€§åŠ è½½è¿‡å¤šæ•°æ®
    all_vectors = []
    batch_size = 1000
    offset = 0
    
    logger.info("å¼€å§‹åˆ†æ‰¹æŸ¥è¯¢å‘é‡...")
    
    while True:
        try:
            # ä½¿ç”¨ query è·å–æ‰€æœ‰æ•°æ®
            # chunk_id æ˜¯ VARCHAR ä¸»é”®ï¼Œä½¿ç”¨ chunk_id != "" æŸ¥è¯¢æ‰€æœ‰éç©ºè®°å½•
            results = collection.query(
                expr='chunk_id != ""',  # æŸ¥è¯¢æ‰€æœ‰è®°å½•ï¼ˆä¸»é”®éç©ºï¼‰
                output_fields=["chunk_id"],
                limit=batch_size,
                offset=offset
            )
            
            if not results:
                break
            
            all_vectors.extend(results)
            offset += len(results)
            
            logger.info(f"å·²æŸ¥è¯¢ {offset} ä¸ªå‘é‡...")
            
            # å¦‚æœè¿”å›çš„è®°å½•æ•°å°‘äº batch_sizeï¼Œè¯´æ˜å·²ç»åˆ°æœ«å°¾
            if len(results) < batch_size:
                break
                
        except Exception as e:
            logger.error(f"æŸ¥è¯¢ Milvus å¤±è´¥ (offset={offset}): {e}")
            break
    
    logger.info(f"ä» Milvus è·å–åˆ° {len(all_vectors)} ä¸ªå‘é‡")
    return all_vectors


def find_orphan_vectors(
    milvus_vectors: List[dict],
    postgres_chunk_ids: Set[str]
) -> List[str]:
    """
    æŸ¥æ‰¾å­¤ç«‹çš„å‘é‡ï¼ˆåœ¨ Milvus ä¸­ä½†ä¸åœ¨ PostgreSQL ä¸­ï¼‰
    
    Args:
        milvus_vectors: Milvus ä¸­çš„å‘é‡åˆ—è¡¨
        postgres_chunk_ids: PostgreSQL ä¸­çš„ chunk_id é›†åˆ
        
    Returns:
        å­¤ç«‹å‘é‡çš„ chunk_id åˆ—è¡¨ï¼ˆMilvus ä¸»é”®ï¼‰
    """
    logger.info("æ­£åœ¨æŸ¥æ‰¾å­¤ç«‹å‘é‡...")
    
    orphan_chunk_ids = []
    
    for vector in milvus_vectors:
        chunk_id = vector.get("chunk_id")
        
        if chunk_id not in postgres_chunk_ids:
            orphan_chunk_ids.append(chunk_id)
    
    logger.info(f"å‘ç° {len(orphan_chunk_ids)} ä¸ªå­¤ç«‹å‘é‡")
    
    if orphan_chunk_ids:
        logger.info("å­¤ç«‹å‘é‡ç¤ºä¾‹ï¼ˆå‰10ä¸ªï¼‰:")
        for i, chunk_id in enumerate(orphan_chunk_ids[:10], 1):
            logger.info(f"  {i}. Chunk ID: {chunk_id}")
    
    return orphan_chunk_ids


def delete_orphan_vectors(
    collection_name: str,
    orphan_chunk_ids: List[str],
    batch_size: int = 100,
    dry_run: bool = True
) -> int:
    """
    åˆ é™¤å­¤ç«‹å‘é‡
    
    Args:
        collection_name: Collection åç§°
        orphan_chunk_ids: è¦åˆ é™¤çš„ chunk_id åˆ—è¡¨ï¼ˆMilvus ä¸»é”®ï¼‰
        batch_size: æ‰¹é‡åˆ é™¤çš„å¤§å°
        dry_run: æ˜¯å¦ä¸ºè¯•è¿è¡Œï¼ˆä¸å®é™…åˆ é™¤ï¼‰
        
    Returns:
        åˆ é™¤çš„å‘é‡æ•°é‡
    """
    if not orphan_chunk_ids:
        logger.info("æ²¡æœ‰å­¤ç«‹å‘é‡éœ€è¦åˆ é™¤")
        return 0
    
    if dry_run:
        logger.warning("=" * 80)
        logger.warning("ğŸ” DRY RUN æ¨¡å¼ - ä¸ä¼šå®é™…åˆ é™¤å‘é‡")
        logger.warning("=" * 80)
        logger.warning(f"å°†è¦åˆ é™¤ {len(orphan_chunk_ids)} ä¸ªå­¤ç«‹å‘é‡")
        return 0
    
    logger.warning("=" * 80)
    logger.warning("âš ï¸  å³å°†åˆ é™¤å­¤ç«‹å‘é‡ï¼")
    logger.warning("=" * 80)
    logger.warning(f"Collection: {collection_name}")
    logger.warning(f"è¦åˆ é™¤çš„å‘é‡æ•°é‡: {len(orphan_chunk_ids)}")
    logger.warning("=" * 80)
    
    # ç¡®è®¤åˆ é™¤
    try:
        confirmation = input("ç¡®è®¤åˆ é™¤ï¼Ÿè¾“å…¥ 'yes' ç»§ç»­: ")
        if confirmation.lower() != 'yes':
            logger.info("æ“ä½œå·²å–æ¶ˆ")
            return 0
    except Exception:
        logger.error("æ— æ³•è·å–ç”¨æˆ·è¾“å…¥ï¼Œæ“ä½œå–æ¶ˆ")
        return 0
    
    milvus_client = get_milvus_client()
    collection = milvus_client.get_collection(collection_name)
    
    if not collection:
        logger.error(f"Collection ä¸å­˜åœ¨: {collection_name}")
        return 0
    
    deleted_count = 0
    
    # åˆ†æ‰¹åˆ é™¤
    for i in range(0, len(orphan_chunk_ids), batch_size):
        batch = orphan_chunk_ids[i:i + batch_size]
        
        try:
            # æ„å»ºåˆ é™¤è¡¨è¾¾å¼
            # æ ¼å¼: chunk_id in ["uuid1", "uuid2", ...]
            ids_str = ", ".join(f'"{chunk_id}"' for chunk_id in batch)
            expr = f"chunk_id in [{ids_str}]"
            
            # æ‰§è¡Œåˆ é™¤
            collection.delete(expr)
            collection.flush()
            
            deleted_count += len(batch)
            logger.info(f"å·²åˆ é™¤ {deleted_count}/{len(orphan_chunk_ids)} ä¸ªå‘é‡")
            
        except Exception as e:
            logger.error(f"åˆ é™¤å‘é‡å¤±è´¥ (batch {i//batch_size + 1}): {e}")
    
    logger.info("=" * 80)
    logger.info(f"âœ“ æˆåŠŸåˆ é™¤ {deleted_count} ä¸ªå­¤ç«‹å‘é‡")
    logger.info("=" * 80)
    
    return deleted_count


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="æ¸…ç† Milvus ä¸­çš„å­¤ç«‹å‘é‡")
    parser.add_argument(
        "--dry-run",
        action="store_true",
        default=True,
        help="è¯•è¿è¡Œæ¨¡å¼ï¼ˆä¸å®é™…åˆ é™¤ï¼Œé»˜è®¤å¯ç”¨ï¼‰"
    )
    parser.add_argument(
        "--force",
        action="store_true",
        help="å¼ºåˆ¶æ‰§è¡Œåˆ é™¤ï¼ˆç¦ç”¨è¯•è¿è¡Œï¼‰"
    )
    parser.add_argument(
        "--collection",
        default=MilvusCollection.DOCUMENTS,
        help=f"Collection åç§°ï¼ˆé»˜è®¤: {MilvusCollection.DOCUMENTS}ï¼‰"
    )
    parser.add_argument(
        "--batch-size",
        type=int,
        default=100,
        help="æ‰¹é‡åˆ é™¤çš„å¤§å°ï¼ˆé»˜è®¤: 100ï¼‰"
    )
    
    args = parser.parse_args()
    
    # ç¡®å®šæ˜¯å¦ä¸ºè¯•è¿è¡Œ
    dry_run = not args.force
    
    try:
        logger.info("=" * 80)
        logger.info("æ¸…ç† Milvus å­¤ç«‹å‘é‡å·¥å…·")
        logger.info("=" * 80)
        logger.info(f"Collection: {args.collection}")
        logger.info(f"æ‰¹é‡å¤§å°: {args.batch_size}")
        logger.info(f"æ¨¡å¼: {'DRY RUN (è¯•è¿è¡Œ)' if dry_run else 'å®é™…åˆ é™¤'}")
        logger.info("=" * 80)
        logger.info("")
        
        # 1. ä» PostgreSQL è·å–æ‰€æœ‰å·²å‘é‡åŒ–çš„ chunk_id
        postgres_chunk_ids = get_all_chunk_ids_from_postgres()
        
        # 2. ä» Milvus è·å–æ‰€æœ‰å‘é‡
        milvus_vectors = get_all_chunk_ids_from_milvus(args.collection)
        
        if not milvus_vectors:
            logger.warning("Milvus ä¸­æ²¡æœ‰å‘é‡ï¼Œæ— éœ€æ¸…ç†")
            return
        
        # 3. æŸ¥æ‰¾å­¤ç«‹å‘é‡
        orphan_chunk_ids = find_orphan_vectors(milvus_vectors, postgres_chunk_ids)
        
        # 4. ç»Ÿè®¡ä¿¡æ¯
        logger.info("")
        logger.info("=" * 80)
        logger.info("ç»Ÿè®¡ä¿¡æ¯:")
        logger.info(f"  PostgreSQL ä¸­å·²å‘é‡åŒ–çš„åˆ†å—æ•°: {len(postgres_chunk_ids):,}")
        logger.info(f"  Milvus ä¸­çš„å‘é‡æ€»æ•°: {len(milvus_vectors):,}")
        logger.info(f"  å­¤ç«‹å‘é‡æ•°é‡: {len(orphan_chunk_ids):,} ({len(orphan_chunk_ids)/len(milvus_vectors)*100:.1f}%)")
        logger.info("=" * 80)
        logger.info("")
        
        # 5. åˆ é™¤å­¤ç«‹å‘é‡
        deleted_count = delete_orphan_vectors(
            collection_name=args.collection,
            orphan_chunk_ids=orphan_chunk_ids,
            batch_size=args.batch_size,
            dry_run=dry_run
        )
        
        if dry_run and orphan_chunk_ids:
            logger.info("")
            logger.info("=" * 80)
            logger.info("ğŸ’¡ æç¤º:")
            logger.info("  è¿™æ˜¯è¯•è¿è¡Œæ¨¡å¼ï¼Œæ²¡æœ‰å®é™…åˆ é™¤å‘é‡")
            logger.info("  è¦æ‰§è¡Œå®é™…åˆ é™¤ï¼Œè¯·è¿è¡Œ:")
            logger.info(f"  python {__file__} --force")
            logger.info("=" * 80)
        
    except KeyboardInterrupt:
        logger.warning("\næ“ä½œå·²è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        logger.error(f"æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        sys.exit(1)


if __name__ == "__main__":
    main()
